# Necesario si installi gcloud
# Necesario si installi kubectl


# CREAZIONE NUOVO PROGETTO:
# gcloud projects create project_name
# Es.
# gcloud projects create base-prj-20240117

# SET PROJECT
# gcloud config set project base-prj-20240117

# INIT PROJECT
# gcloud init

# SET ZONE E REGIONE
# visualizzazione zone a disposizione
# 1. abilitare fatturazione del servizio API Compute Engine all’interno di google cloud platform (https://console.cloud.google.com/apis/library?project=base-prj-20240117)

# gcloud compute zones list

# 2. si visualizzi la lista delle zone:
#  europe-west12-a
# all'interno della sezione configurazione macchina, presente al link https://gcloud-compute.com/instances.html
# si riscontra, in modo immediato, il costo effettivo, corrispondente alle varie aree geografiche, dell'istanza selezionata.

# 3.set zona:
# gcloud config set compute/zone zone_name
# es.
# gcloud config set compute/zone us-central1-c 

# 4. verifica property:
# gcloud info 

# 5. si visualizzi la lista delle regioni:
# gcloud compute regions list

# 6.set zona regione:
# gcloud config set compute/region nome_regione
# es.
# gcloud config set compute/region us-central1

# 7. verifica property:
# gcloud info 

# # CREAZIONE CLUSTER
# 1. Abilitazione kubernates Engine API
# 2. Abilitazione container.googleapis.com
# gcloud services enable container.googleapis.com
# 3. Creazione cluster
# to test -> gcloud container clusters create base-prj-20240117- cls--num-nodes 1 --machine-type e2-standard-2 --no-enable-autoscaling --max-pods-per-node 200 --enable-ip-alias
# gcloud container clusters create base-prj-20240117-cls --num-nodes 1 --machine-type e2-standard-2 --no-enable-autoscaling

# # BASE PROJECT

# # ************* CREAZIONE NETWORK POLICIES *************
# SI VERIFICHI ATTRAVERSO LA PROPERTY networkPolicyConfig L'ABILITAZIONE DEL CLUSTER ALLE NETWORK POLICIES
# gcloud container clusters describe base-prj-20240117-cls --zone us-central1-c 
# IN CASO DI NETWORK POLICIES NON ABILITATE:
# gcloud container clusters update base-prj-20240117-cls --update-addons=NetworkPolicy=ENABLED --zone us-central1-c 
# QUINDI:
# gcloud container clusters update base-prj-20240117-cls --enable-network-policy

# # ************* CREAZIONE DB *************
# # LISTA CLUSTER
# gcloud container clusters list
# # CREAZIONE DB (name= mysqldb)
# gcloud compute disks create --size=10GiB --zone=us-central1-c mysqldb
# gcloud compute disks list
# # SI CREI UN PERSISTENT VOLUME, CREAMO QUINDI SPAZIO
# kubectl create -f persistentVolumes/mysql-pv.yml
# kubectl get PersistentVolumes
# # SI CREI UN PERSISTENT VOLUME CLAIM, UILIZIAMO QUINDI, LO SPAZIO CREATO CON pv
# kubectl create -f persistentVolumesClaims/mysql-pvc.yml
# kubectl get PersistentVolumeClaim

# SI VERIFICHI IL QUANTITATIVO DI CPU E MEMORIA A DISPOSIZIONE 
# PER DIMENSIONARE COSI' IN MODO CORRETTO I POD. SI VERIFICHINO QUINDI LE PROPERTY Allocatable:  cpu: E memory:
# SI CONSIDERI INOLTRE 1core = 1000millicores = 1000m
# kubectl describe nodes

# # ************* CREAZIONE POD DB *************
# kubectl create -f deployments/mysql-dep.yml

# UPLOAD SCHEMA ALL'INTERNO DEL POD mysqldb
# 1. si entri nel pod in bash
# kubectl exec -ti mysql-deployment-656c9b55fc-rm6vw -- bash
# 2. si crei una folder: dump
# 3. dalla macchia locale, si effettui l'upload dello schema
# kubectl cp db/dump20240118.sql mysql-deployment-656c9b55fc-rm6vw:/dump
# 4. si entri nel pod in bash
# 5. si crei il database:
# mysql -p 
# 20210821Ta!
# create database Base;
# exit;
# mysql -p --database=Base < /dump/dump20240118.sql
# 6. si crei l'utenza dal quale avranno accesso i microservizi:
# mysql -p 
# CREATE USER 'msUser'@'%';
# to test > GRANT ALL PRIVILEGES ON base.* To 'msUser'@'%' IDENTIFIED BY '20210821Bp!';
# GRANT ALL PRIVILEGES ON *.* TO 'msUser'@'%' IDENTIFIED BY '20210821Bp!';
# exit;
# exit
# # ************* CREAZIONE SERVICE DB *************
# kubectl create -f services/mysql-srv.yml

# # ************* CREAZIONE CONFIG MAP MS-ZUUL ************* 
# kubectl create configmap ms-zuul-config --from-literal=springProfile=struct1 --from-literal=MsUserIp=ms-user-gke-service
# # ************* CREAZIONE DEPLOYMENT MS-ZUUL *************
# kubectl create -f deployments/zuul-dep.yml
# # ************* CREAZIONE SERVICE MS-ZUUL *************
# 1. Creazione external static IP
# REGION=$(gcloud config get-value compute/region)
# gcloud compute addresses create zuul-kube-service-static-ip --region=${REGION}
# Es.
# gcloud compute addresses create zuul-gke-service-static-ip --region=us-central1
# 2. Sostituire, all'interno dell'zuul-srv:
# la proprietà loadBalancerIP. Si valorizzi tale proprietà con l'IP genereato.
# to test -> la proprietà loadBalancerSourceRanges, con la subnetmask, dell'ip statico presente all'interno della variabie ingress-kube-service-static-ip. Tale configurazione limita l'accesso al kube-service.
# 3. Si crei l'instanza kube-service
# kubectl create -f services/zuul-srv.yml

# # ************* CREAZIONE CONFIG MAP MS-USER *************
# kubectl create configmap ms-user-config --from-literal=springProfile=struct1 --from-literal=MySqlIp=mysql-gke-service --from-literal=ZuulIp=zuul-gke-service
# # ************* CREAZIONE DEPLOYMENT MS-USER *************
# kubectl create -f deployments/ms-user-dep.yml
# # ************* CREAZIONE SERVICE MS-USER *************
# 1. Creazione external static IP
# REGION=$(gcloud config get-value compute/region)
# gcloud compute addresses create ms-user-gke-service-static-ip --region=${REGION}
# Es.
# gcloud compute addresses create ms-user-gke-service-static-ip --region=us-central1
# 2. Sostituire, all'interno dell'associations-srv:
# la proprietà loadBalancerIP. Si valorizzi tale proprietà con l'IP genereato
# la proprietà loadBalancerSourceRanges con la subnetmask degli ip statici presenti all'interno della variabie: zuul-kube-service-static-ip, runners-kube-service-static-ip. Tale configurazione limita l'accesso al kube-service.
# 3. Si crei l'instanza ms-user-gke-service
# kubectl create -f services/ms-user-srv.yml

# # ********** APPLICAZIONE NETWORK POLICIES **********
# Si abilitano le network policies al POD ms-user
# kubectl apply -f netwokrPolicy/ms-user-net-pol.yml 
# Si abilitano le network policies al POD mysql
# kubectl apply -f netwokrPolicy/mysql-net-pol.yml 

# *****************************************************************************
# CREAZIONE SISTEMA AUTOMATIZZATO PER L'ACCENSIONE E LO SPEGNIMENTO DEL CLUSTER
# *****************************************************************************
# TALE PROCEDURA VERIFICA 4 STEP:
# 1. CREAZIONE DEL PUB/SUB, ESSO RAPPRESENTA UN URL CHE SARA' ASSOCIATO ALLA FUNCTION CLOUD PER ESSERE RICHIAMATA
# 2. CREAZIONE DI UNA FUNCTION IN node.js CHE, DATO JSON IN INGRESSO SCALA UN DATO CLUSTER
# 3. CREAZIONE JOB DI ACCENSIONE E SPEGNIMENTO. ESSI, VERRANNO COSI' AVVIATI AUTOMATICAMENTE E RICHIAMERANNO LA FUNCTION
# CHE SCALERA' IL CLUSTER SECONDO QUANTO DESIDERATO.

# # ************* CREAZIONE PUB/SUB *************
# gcloud pubsub topics create scale-gke-event

# # ************* CREAZIONE FUNCTION *************
# SI CREI, ALL'INTERNO DELLA SEZIONE GOOGLE CLOUD FUNCTION UNA FUNCTION SEGUENDO GLI STEP DEFINITI ALL'INTERNO 
# DEGLI SCREENSHOT doc/config/cloud_function/cloud_functio_0 , doc/config/cloud_function/cloud_functio_1
# SI SELEZIONI, COME RUNTIME node.JS 18
# SI SOVRASCRIVA IL FILE index.js CON QUANTO PRESENTE ALL'INTERNO DELLA FOLDER doc/config/cloud_function/index.js
# SI SOVRASCRIVA IL FILE package.json CON QUANTO PRESENTE ALL'INTERNO DELLA FOLDER doc/config/cloud_function/package.json
# SI SETTI, ALL'INTERNO DI GOOGLE CLOUD FUNCTION, L'ENTY POINT IN scalegkePubSub COME PRESENTE IN FIGURA doc/config/cloud_function/cloud_functio_2
# SI ESEGUA IL DEPLOYMENT

# ************* CREAZIONE JOB SCHEDULER ACCENSIONE SPEGNIMENTO *************
# SI ACCEDA ALLA SEZIONE  CLOUD SCHEDULER
# SI CREI IL JOB gke-scale-down E SI DEFINISCA LA PIANIFICAZIONE DESIDERATA. LA FIGURA doc/config/cloud_function/cloud_functio_3 DESCRIVE UN ESEMPIO, QUINDI SI SELEZIONI CONTINUA
# SI CONFIGURI L'ESECUZIONE SECONDO QUANDO DEFINITO IN FIGURA doc/config/cloud_function/cloud_functio_4 E SI POPOLI LA SEZIONE 'Corpo del messaggio' INSERENDO QUINDI
# IL JSON CHE LA FUNCTION CLOUD, PRECEDENTEMENTE REALIZZTA SI ATTENDE (SI INSERISCANO, PER LE DIFFEENTI PROPERTIES GLI OPPORTUNI DATI):
{ 
  "projectId": "base-prj-20240117", 
  "zone": "us-central1-c", 
  "cluster_id": "base-prj-20240117-cls", 
  "node_pool_id": "default-pool", 
  "node_count": 0
}
# SI SALVI

# ************* CREAZIONE JOB SCHEDULER ACCENSIONE ACCENSIONE *************
# SI UTILIZZI LA MEDESIMA PROCEDURA PER LO SPEGNIMENTO, ANDANDO A RIVALORIZZARE LA PIANIFICAZIONE DESIDERATA
# E PORTANDO AD 1 MINIMO IL NUMERO DI NODI DEL CLUSTER QUINDI "node_count": 1

# *****************************************************************************
# ***************************** FINE ******************************************
# *****************************************************************************